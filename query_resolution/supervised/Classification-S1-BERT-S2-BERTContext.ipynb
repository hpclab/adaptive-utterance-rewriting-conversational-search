{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle(\"../../data/datasets/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only use this for the \"doc\" field and NOT for prediction\n",
    "test_features_s1 = pd.read_pickle(\"../../data/gbdt_features/test_features_step1.pkl\")\n",
    "cols = test_features_s1.columns[2:]\n",
    "np_test_features_s1 = test_features_s1[cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 after Step 1 BERT\n",
    "# we only use this for the \"doc\" field and NOT for prediction\n",
    "test_features_s2 = pd.read_pickle(\"../../data/gbdt_features/test_features_step2_all_feat_lightGBM_S1_BERT.pkl\")  # computed on results of STEP1 \n",
    "cols = test_features_s2.columns[2:]\n",
    "np_test_features_s2 = test_features_s2[cols].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use predicted labels from file instead of running the model in inference\n",
    "predFile_Step1 = \"../../data/bert_models/pred_BERT_MSMARCO_step1.tsv\"\n",
    "pred_df_step1 = pd.read_csv(predFile_Step1, delimiter=\"\\t\", header=None)\n",
    "\n",
    "pred_df_step1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use predicted labels from file instead of running the model in inference\n",
    "predFile_Step2 = \"../../data/bert_models/pred_BERT_MSMARCO_step2.tsv\"\n",
    "pred_df_step2 = pd.read_csv(predFile_Step2, delimiter=\"\\t\", header=None)\n",
    "\n",
    "pred_df_step2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble results and simulate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = list(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result dict is a dictionary:\n",
    "# - key: qid \n",
    "# - value: a tuple of (predicted_label, groundtruth_label, original_utterance)\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for i in test_index:\n",
    "    utt_id = test_df[0][i]\n",
    "    if (test_df[0][i].split(\"_\")[1]==str(1)):\n",
    "        result_dict[test_df[0][i]] = (\"SE\", test_df[2][i], test_df[1][i])\n",
    "    else:\n",
    "        # predictions for STEP 1\n",
    "        result_step1 = pred_df_step1[2][i]\n",
    "        if result_step1==1:\n",
    "            result_dict[test_df[0][i]] = (\"SE\", test_df[2][i], test_df[1][i])\n",
    "        else:\n",
    "            # predictions for STEP 2\n",
    "            aux = pred_df_step2.loc[pred_df_step2[0]==utt_id]\n",
    "            result_step2 = int(aux[4])\n",
    "            if result_step2 == 1:\n",
    "                result_dict[test_df[0][i]] = (\"FT\", test_df[2][i], test_df[1][i])\n",
    "            else:\n",
    "                result_dict[test_df[0][i]] = (\"PT\", test_df[2][i], test_df[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict # predicted vs ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = 0\n",
    "for a,b,c in result_dict.values():\n",
    "    if a ==b==\"SE\":\n",
    "        true_pos += 1\n",
    "    if (a==b==\"FT\") or (a==b==\"PT\"):\n",
    "        true_pos += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy {}/{} is : {}\".format(true_pos, 194, true_pos/194.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_test = test_df[2].values\n",
    "y_pred = [a for a,b,c in result_dict.values()]\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, labels=[\"SE\", \"FT\", \"PT\"]))\n",
    "print(classification_report(y_test, y_pred, labels=[\"SE\", \"FT\", \"PT\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utterance rewriting strategies for post-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topic_utils import create_doc, _find_topic, _rewrite_utt, _find_cue_topic, _find_topic_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 1: Standard - Enrich with first or previous topic\n",
    "- extract first and previous topic and rewrite utterance \n",
    "- if missing third person pronoun we trail either first or previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_Standard(test_df, pred_df_step1, pred_df_step2, test_features_s2):\n",
    "    \"\"\"\n",
    "    Enrich with first or previous topic\n",
    "    - extract first and previous topic and rewrite utterance\n",
    "    - if missing third person pronoun we trail either first or previous\n",
    "    :param test_df: the test dataset\n",
    "    :param pred_df_step1: predictions dataframe for Step1 (we don't use the model,\n",
    "    we just assemble the results)\n",
    "    :param pred_df_step2: predictions dataframe for Step1\n",
    "    :param test_features_s2: features dataframe for which we use the doc object\n",
    "    (with the nlp by spacy) for rewriting\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    test_index = list(test_df.index)\n",
    "    result_dict = {}\n",
    "\n",
    "    for i in test_index:\n",
    "        utt_id = test_df[0][i]\n",
    "        if test_df[0][i].split(\"_\")[1] == str(1):\n",
    "            result_dict[test_df[0][i]] = test_df[1][i]\n",
    "        else:\n",
    "            # STEP 1\n",
    "            result_step1 = pred_df_step1[2][i]\n",
    "            if result_step1 == 1:\n",
    "                result_dict[test_df[0][i]] = test_df[1][i]\n",
    "            else:\n",
    "                # STEP 2\n",
    "                aux = pred_df_step2.loc[pred_df_step2[0] == utt_id]\n",
    "                result_step2 = int(aux[4])\n",
    "\n",
    "                current_doc = test_features_s2.at[i, \"doc\"]\n",
    "\n",
    "                if result_step2 == 1:\n",
    "                    # get the first topic\n",
    "                    conv_id = test_df[0][i].split(\"_\")[0]\n",
    "                    first_utt_id = conv_id + \"_1\"\n",
    "                    row_index_first = test_features_s2.index[\n",
    "                        test_features_s2[0] == first_utt_id].tolist()[0]\n",
    "                    first_utt_doc = test_features_s2.at[row_index_first, \"doc\"]\n",
    "                    first_topic = _find_topic(first_utt_doc)\n",
    "\n",
    "                    new_utt = _rewrite_utt(current_doc, first_topic=first_topic,\n",
    "                                           previous_topic=\"\", context_list=None,\n",
    "                                           trailing=True)\n",
    "                    result_dict[test_df[0][i]] = new_utt\n",
    "                else:\n",
    "                    # get the previous topic\n",
    "                    prev_utt_id = test_df[0][i - 1]\n",
    "                    row_index_previous = test_features_s2.index[\n",
    "                        test_features_s2[0] == prev_utt_id].tolist()[0]\n",
    "                    prev_utt_doc = test_features_s2.at[\n",
    "                        row_index_previous, \"doc\"]\n",
    "                    prev_topic = _find_topic(prev_utt_doc)\n",
    "\n",
    "                    new_utt = _rewrite_utt(current_doc, first_topic=\"\",\n",
    "                                           previous_topic=prev_topic,\n",
    "                                           context_list=None, trailing=True)\n",
    "                    result_dict[test_df[0][i]] = new_utt\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = strategy_Standard(test_df, pred_df_step1, pred_df_step2, test_features_s2)\n",
    "list(result_dict.items())[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: Extract PT on enriched utterance\n",
    "\n",
    "- just like Strategy 1 but for PT we extract on enriched utterance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_Enriched(test_df, pred_df_step1, pred_df_step2, test_features_s2):\n",
    "    \"\"\"\n",
    "    Similar to Strategy Standard but for PT we extract on enriched utterance\n",
    "    :param test_df: the test dataset\n",
    "    :param pred_df_step1: predictions dataframe for Step1 (we don't use the model,\n",
    "    we just assemble the results)\n",
    "    :param pred_df_step2: predictions dataframe for Step1\n",
    "    :param test_features_s2: features dataframe for which we use the doc object\n",
    "    (with the nlp by spacy) for rewriting\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    test_index = list(test_df.index)\n",
    "    result_dict = {}\n",
    "    enriched_utt_dict = {}\n",
    "\n",
    "    for i in test_index:\n",
    "        utt_id = test_df[0][i]\n",
    "        if test_df[0][i].split(\"_\")[1] == str(1):\n",
    "            result_dict[test_df[0][i]] = (\"SE\", test_df[1][i])\n",
    "            enriched_utt_dict[i] = test_df[1][i]\n",
    "        else:\n",
    "            # STEP 1\n",
    "            result_step1 = pred_df_step1[2][i]\n",
    "            if result_step1 == 1:\n",
    "                result_dict[test_df[0][i]] = (\"SE\", test_df[1][i])\n",
    "                enriched_utt_dict[i] = test_df[1][i]\n",
    "            else:\n",
    "                # STEP 2\n",
    "                aux = pred_df_step2.loc[pred_df_step2[0] == utt_id]\n",
    "                result_step2 = int(aux[4])\n",
    "\n",
    "                current_doc = test_features_s2.at[i, \"doc\"]\n",
    "\n",
    "                if result_step2 == 1:\n",
    "                    # get the first topic\n",
    "                    conv_id = test_df[0][i].split(\"_\")[0]\n",
    "                    first_utt_id = conv_id + \"_1\"\n",
    "                    row_index_first = test_features_s2.index[\n",
    "                        test_features_s2[0] == first_utt_id].tolist()[0]\n",
    "                    first_utt_doc = test_features_s2.at[row_index_first, \"doc\"]\n",
    "                    first_topic = _find_topic(first_utt_doc)\n",
    "\n",
    "                    new_utt = _rewrite_utt(current_doc, first_topic=first_topic,\n",
    "                                           previous_topic=\"\", context_list=None,\n",
    "                                           trailing=True)\n",
    "                    result_dict[test_df[0][i]] = (\"FT\", new_utt)\n",
    "                    enriched_utt_dict[i] = new_utt\n",
    "                else:\n",
    "                    # get the previous topic\n",
    "                    # this changes respect to Strategy 1\n",
    "                    prev_utt_doc = create_doc(enriched_utt_dict[i - 1])\n",
    "                    prev_topic = _find_topic(prev_utt_doc)\n",
    "\n",
    "                    new_utt = _rewrite_utt(current_doc, first_topic=\"\",\n",
    "                                           previous_topic=prev_topic,\n",
    "                                           context_list=None, trailing=True)\n",
    "                    result_dict[test_df[0][i]] = (\"PT\", new_utt)\n",
    "                    enriched_utt_dict[i] = new_utt\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = strategy_Enriched(test_df, pred_df_step1, pred_df_step2, test_features_s2)\n",
    "list(result_dict.items())[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 3:\n",
    "\n",
    "- propagate everything from the last SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_Last_SE(test_df, pred_df_step1, test_features_s2):\n",
    "    \"\"\"\n",
    "    Propagate everything from the last SE\n",
    "    :param test_df: the test dataset\n",
    "    :param pred_df_step1: predictions dataframe for Step1 (we don't use the model,\n",
    "    we just assemble the results)\n",
    "    :param test_features_s2: features dataframe for which we use the doc object\n",
    "    (with the nlp by spacy) for rewriting\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    test_index = list(test_df.index)\n",
    "    result_dict = {}\n",
    "    last_SE_topic = \"\"\n",
    "\n",
    "    for i in test_index:\n",
    "        if test_df[0][i].split(\"_\")[1] == str(1):\n",
    "            result_dict[test_df[0][i]] = test_df[1][i]\n",
    "            last_SE_topic = _find_topic(test_features_s2[\"doc\"][i])\n",
    "\n",
    "        else:\n",
    "            resultSE = pred_df_step1[2][i]\n",
    "            if resultSE == 1:\n",
    "                result_dict[test_df[0][i]] = test_df[1][i]\n",
    "                last_SE_topic = _find_topic(test_features_s2[\"doc\"][i])\n",
    "\n",
    "            else:\n",
    "                current_doc = test_features_s2.at[i, \"doc\"]\n",
    "                new_utt = _rewrite_utt(current_doc, first_topic=\"\",\n",
    "                                       previous_topic=last_SE_topic,\n",
    "                                       context_list=None, trailing=True)\n",
    "                result_dict[test_df[0][i]] = new_utt\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = strategy_Last_SE(test_df, pred_df_step1, test_features_s2)\n",
    "list(result_dict.items())[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 4: \n",
    "\n",
    "- propagate everything from the last SE and keep FT for context (expand for all previous also with first! , similar to trailing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_First_and_Last_SE(test_df, pred_df_step1, test_features_s2):\n",
    "    \"\"\"\n",
    "    Propagate everything from the last SE and keep FT for context\n",
    "    (expand for all previous also with first!, similar to trailing)\n",
    "    :param test_df: the test dataset\n",
    "    :param pred_df_step1: predictions dataframe for Step1 (we don't use the model,\n",
    "    we just assemble the results)\n",
    "    :param test_features_s2: features dataframe for which we use the doc object\n",
    "    (with the nlp by spacy) for rewriting\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    test_index = list(test_df.index)\n",
    "    result_dict = {}\n",
    "    last_SE_topic = \"\"\n",
    "    first_SE_topic = \"\"\n",
    "\n",
    "    for i in test_index:\n",
    "        if test_df[0][i].split(\"_\")[1] == str(1):\n",
    "            result_dict[test_df[0][i]] = test_df[1][i]\n",
    "\n",
    "            last_SE_topic = _find_topic(test_features_s2[\"doc\"][i])\n",
    "            first_SE_topic = last_SE_topic\n",
    "\n",
    "        else:\n",
    "            resultSE = pred_df_step1[2][i]\n",
    "            if resultSE == 1:\n",
    "                result_dict[test_df[0][i]] = test_df[1][i] + \" \" + first_SE_topic\n",
    "                last_SE_topic = _find_topic(test_features_s2[\"doc\"][i])\n",
    "\n",
    "            else:\n",
    "                current_doc = test_features_s2.at[i, \"doc\"]\n",
    "                new_utt = _rewrite_utt(current_doc, first_topic=\"\",\n",
    "                                       previous_topic=last_SE_topic,\n",
    "                                       context_list=None, trailing=True)\n",
    "                result_dict[test_df[0][i]] = new_utt + \" \" + first_SE_topic\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = strategy_First_and_Last_SE(test_df, pred_df_step1, test_features_s2)\n",
    "list(result_dict.items())[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 5:\n",
    "\n",
    "If FT enrich with first SE. If PT enrich with last SE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_First_or_Last_SE(test_df, pred_df_step1, pred_df_step2, test_features_s2):\n",
    "    \"\"\"\n",
    "    If FT enrich with first SE. If PT enrich with last SE.\n",
    "    :param test_df: the test dataset\n",
    "    :param pred_df_step1: predictions dataframe for Step1 (we don't use the model,\n",
    "    we just assemble the results)\n",
    "    :param pred_df_step2: predictions dataframe for Step1\n",
    "    :param test_features_s2: features dataframe for which we use the doc object\n",
    "    (with the nlp by spacy) for rewriting\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    test_index = list(test_df.index)\n",
    "    result_dict = {}\n",
    "    last_SE_topic = \"\"\n",
    "    first_SE_topic = \"\"\n",
    "\n",
    "    for i in test_index:\n",
    "        utt_id = test_df[0][i]\n",
    "        if test_df[0][i].split(\"_\")[1] == str(1):\n",
    "            result_dict[test_df[0][i]] = test_df[1][i]\n",
    "            last_SE_topic = _find_topic_all(test_features_s2[\"doc\"][i])\n",
    "            first_SE_topic = last_SE_topic\n",
    "\n",
    "        else:\n",
    "            # STEP 1\n",
    "            result_step1 = pred_df_step1[2][i]\n",
    "            if result_step1 == 1:\n",
    "                result_dict[test_df[0][i]] = test_df[1][i]\n",
    "                last_SE_topic = _find_topic_all(test_features_s2[\"doc\"][i])\n",
    "            else:\n",
    "                # STEP 2\n",
    "                aux = pred_df_step2.loc[pred_df_step2[0] == utt_id]\n",
    "                result_step2 = int(aux[4])\n",
    "\n",
    "                current_doc = test_features_s2.at[i, \"doc\"]\n",
    "\n",
    "                if result_step2 == 1:\n",
    "                    new_utt = _rewrite_utt(current_doc,\n",
    "                                           first_topic=first_SE_topic,\n",
    "                                           previous_topic=\"\", context_list=None,\n",
    "                                           trailing=True)\n",
    "                    result_dict[test_df[0][i]] = new_utt\n",
    "                else:\n",
    "                    new_utt = _rewrite_utt(current_doc, first_topic=\"\",\n",
    "                                           previous_topic=last_SE_topic,\n",
    "                                           context_list=None, trailing=True)\n",
    "                    result_dict[test_df[0][i]] = new_utt\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = strategy_First_or_Last_SE(test_df, pred_df_step1, pred_df_step2, test_features_s2)\n",
    "list(result_dict.items())[:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
